import Head from "next/head";
import RecordButton from "@/components/record-button";
import ProcessButton from "@/components/process-button";
import AudioPlayer from "@/components/audio-player";
import Transcription from "@/components/transcription";

import { useAudioController } from "@/controllers/audio.controller";

export default function Home() {
  const {
    isRecording,
    audioBlob,
    transcription,
    error,
    toggleRecording,
    handleTranscribe,
  } = useAudioController();

  return (
    <>
      <Head>
        <title>OpenAI Speech Transcriber</title>
        <meta name="description" content="Generated by create next app" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="icon" href="/favicon.ico" />
      </Head>

      <main className="main-container">
        <h1>Transcrição de Áudio com OpenAI Whisper</h1>

        <RecordButton
          isRecording={isRecording}
          toggleRecording={toggleRecording}
        />
        <ProcessButton onClick={handleTranscribe} isDisabled={!audioBlob} />

        {audioBlob && <AudioPlayer blob={audioBlob} />}
        <Transcription transcription={transcription} error={error} />
      </main>
    </>
  );
}
